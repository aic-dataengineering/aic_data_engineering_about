# 🏗️ aic_data_engineering_about

Welcome to the **AIC Data Engineering** team's home! This repository serves as a central hub for everything related to data engineering within the AIC cluster — from ingestion pipelines to infrastructure frameworks, standards, and best practices.

---

## 📌 Purpose

Our mission is to **enable scalable, reliable, and efficient data movement and transformation** across the organization. We build and maintain the foundational systems that power analytics, machine learning, and digital products.

---

## 🧱 What We Do

### 🔄 Data Ingestion
- Batch and real-time data ingestion from internal and external sources
- Building connectors and ingestion templates
- Data source documentation and cataloging

### 🏗️ Data Infrastructure & Frameworks
- Frameworks for building ETL/ELT pipelines
- Config-driven orchestration using tools like Airflow, Prefect, or custom engines
- Standards for Spark, SQL, and Python-based pipelines

### 🧰 Tooling and Automation
- Development of reusable tooling for validation, monitoring, and logging
- CI/CD for data pipelines
- Versioning and metadata management

### 📦 Data Lakehouse Architecture
- Delta Lake / Lakehouse setup and management
- Partitioning, optimization, and cost-aware storage strategies

---

## 🧪 Standards and Best Practices

We follow a set of internal conventions to ensure our pipelines are:
- **Modular**
- **Testable**
- **Auditable**
- **Reproducible**
- **Secure by default**

See [`docs/standards.md`](./docs/standards.md) for details.

---

## 🧑🏽‍💻 Team Structure

- **Data Engineering Lead**: Thabang M.
- **Collaborators**: Data Scientists, MLOps, Platform Engineers
- **Slack Channel**: `#aic-data-engineering`

---

## 📂 Repo Structure

