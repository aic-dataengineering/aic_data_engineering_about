# ğŸ—ï¸ aic_data_engineering_about

Welcome to the **AIC Data Engineering** team's home! This repository serves as a central hub for everything related to data engineering within the AIC cluster â€” from ingestion pipelines to infrastructure frameworks, standards, and best practices.

---

## ğŸ“Œ Purpose

Our mission is to **enable scalable, reliable, and efficient data movement and transformation** across the organization. We build and maintain the foundational systems that power analytics, machine learning, and digital products.

---

## ğŸ§± What We Do

### ğŸ”„ Data Ingestion
- Batch and real-time data ingestion from internal and external sources
- Building connectors and ingestion templates
- Data source documentation and cataloging

### ğŸ—ï¸ Data Infrastructure & Frameworks
- Frameworks for building ETL/ELT pipelines
- Config-driven orchestration using tools like Airflow, Prefect, or custom engines
- Standards for Spark, SQL, and Python-based pipelines

### ğŸ§° Tooling and Automation
- Development of reusable tooling for validation, monitoring, and logging
- CI/CD for data pipelines
- Versioning and metadata management

### ğŸ“¦ Data Lakehouse Architecture
- Delta Lake / Lakehouse setup and management
- Partitioning, optimization, and cost-aware storage strategies

---

## ğŸ§ª Standards and Best Practices

We follow a set of internal conventions to ensure our pipelines are:
- **Modular**
- **Testable**
- **Auditable**
- **Reproducible**
- **Secure by default**

See [`docs/standards.md`](./docs/standards.md) for details.

---

## ğŸ§‘ğŸ½â€ğŸ’» Team Structure

- **Data Engineering Lead**: Thabang M.
- **Collaborators**: Data Scientists, MLOps, Platform Engineers
- **Slack Channel**: `#aic-data-engineering`

---

## ğŸ“‚ Repo Structure

